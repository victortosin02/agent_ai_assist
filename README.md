<<<<<<< HEAD
# Real-Time AI Assistance for Call Center Agents

Introduction:
Conversational AI is currently attracting great attention in various industries such as smart home, customer service, and especially automated call centers. Traditional call center systems require significant workforces to handle customer inquiries, resulting in increased companies' operation costs. Many companies have sought to automate call centers by implementing their own customized interactive voice response systems or benefiting from one of the various commercial, off-the-shelf systems. However, these traditional conversational agents have several limitations. These agents typically require a well-structured interaction design and strictly processed user input. For example, if the users do not select the appropriate number or manually input information about their identities and intentions, traditional call center agents would be difficult to properly understand and help solve the users' inquiries. This results in a high customer churn rate. Furthermore, traditional conversational agents implement scripted and flow-guided dialogs, which makes agents straightforward. Given the ever-growing customer service terrain, call center agents of today need efficient tools in order to be able to tackle issues quicker and with better results. The crux of much of this growing needs lie more in situation when those that need help and or want to know more about what you have available, reach out with questions or ask for assistance. This moment, right here is when a relationship with the customer either blooms or wilts. Unfortunately for many contact centers, they suffer from an onerous and antiquated queue mechanism that results in excessive chances to wait in a long line only to be evenly distributed across limited seats. Overall this traditional process can be revolutionized by integrating artificial intelligence components such as generative models like Nebula LLM of Symbl AI into platforms such as Amazon Connect powered by services like Amazon Kinesis. ⁤ ⁤
Bearing in mind the need to assist contact center agents with real-time intelligent assistance, this tutorial explains steps to integrate asynchronous Amazon Connect with Symbl calls to enhance its real-time speech to text capabilities and transform call centers. The architecture follows a serverless design, thus minimizing the need to support physical on-premise infrastructure. By implementing this solution, technical architects can save additional development skills, including telephony and machine learning, to focus on custom business use-case requirements. This provides a great way to transform call centers faster and create meaningful experiences for agents and a more reliable and secure environment for organizations.


Why Use Symbl.ai Over Amazon Connect's Generative AI Feature?

As a relatively young market with multiple players, contact centers can sometimes find it challenging to choose a specific technology to satisfy their needs. In this section of the tutorial, we will provide developers an extensive comparative analysis of the two technologies (Symbl.ai and Amazon Connect Generative AI) often used by Contact Centers to help businesses make a more informed decision and why we have a more favored inclination towards Symbl.ai when it comes to providing real-time assistance to contact center agents. We study the AI-powered Symbl.ai technology, which is a cloud-based API platform for processing conversation data, and the Amazon Connect technology, which is a cloud service that enables businesses to automate and improve the customer experience they deliver to their customers. Below is an elaborate explanation from different thematic concerns to futher understand why you should use Symbl.ai Over Amazon Connect's Generative AI Feature.

Specialized Conversational Intelligence
Symbl.ai specializes in advanced conversational intelligence, offering capabilities that go beyond simple generative responses and real-time transcription. Its features, such as sentiment analysis, topic extraction, conversation summarization, action item detection, and follow-up tracking, provide a deeper understanding of customer interactions and enhance agent productivity. In contrast, Amazon Connect's Generative AI primarily focuses on streamlining queue selection and handling natural language inputs, making it effective for improving queue selection through natural language descriptions, but lacking the same depth of conversational analysis as Symbl.ai.

Real-Time and Post-Conversation Insights
With comprehensive analytics suite offerings, Symbl.ai provides both real-time and post-conversation insights, which are essential for immediate customer support and long-term strategic planning. Its real-time capabilities, including live transcription and contextual understanding, significantly enhance agent performance and customer satisfaction. Amazon Connect's Generative AI, on the other hand, primarily focuses on improving the customer interaction process during the call, particularly in queue selection, but may lack the comprehensive post-conversation insights offered by Symbl.ai, limiting its utility for ongoing improvements and strategic analysis.

Scalability and Cross-Platform Support
In terms of flexibility and adaptability, Symbl.ai boasts a platform-agnostic design enabling seamless integration across various communication channels such as phone, web, social media, and more, providing a consistent conversational experience across different platforms, which is ideal for businesses with diverse communication needs. In contrast, Amazon Connect's Generative AI is tightly integrated with the Amazon Connect ecosystem, offering an advantage for users deeply embedded in the AWS infrastructure, but potentially limiting its versatility when integrating with non-AWS platforms or across multiple communication channels.

Developer and User Community Support
=======
## Real-Time AI Assistance for Call Center Agents

## Introduction:
In today's fast-paced customer service landscape, call center agents need efficient tools to resolve issues quickly and effectively. This tutorial will guide developers in integrating Amazon Connect and Symbl.ai using Amazon Kinesis to create an AI assistant with Symbl.ai Trackers and Nebula LLM. This solution aims to provide call center agents with real-time AI assistance, enhancing their troubleshooting capabilities and improving customer satisfaction.

## Why Use Symbl.ai Over Amazon Connect's Generative AI Feature?
When comparing Symbl.ai to Amazon Connect's generative AI feature for transforming contact center experiences, there are several distinct advantages that Symbl.ai offers, particularly in terms of flexibility, depth of integration, and specialized capabilities. Here’s a detailed look at why you might choose Symbl.ai over Amazon Connect's generative AI:

**Specialized Conversational Intelligence**
Symbl.ai specializes in advanced conversational intelligence, offering capabilities that go beyond simple generative responses and real-time transcription. Its features, such as sentiment analysis, topic extraction, conversation summarization, action item detection, and follow-up tracking, provide a deeper understanding of customer interactions and enhance agent productivity. In contrast, Amazon Connect's Generative AI primarily focuses on streamlining queue selection and handling natural language inputs, making it effective for improving queue selection through natural language descriptions, but lacking the same depth of conversational analysis as Symbl.ai.

**Real-Time and Post-Conversation Insights**
With comprehensive analytics suite offerings, Symbl.ai provides both real-time and post-conversation insights, which are essential for immediate customer support and long-term strategic planning. Its real-time capabilities, including live transcription and contextual understanding, significantly enhance agent performance and customer satisfaction. Amazon Connect's Generative AI, on the other hand, primarily focuses on improving the customer interaction process during the call, particularly in queue selection, but may lack the comprehensive post-conversation insights offered by Symbl.ai, limiting its utility for ongoing improvements and strategic analysis.

**Scalability and Cross-Platform Support**
In terms of flexibility and adaptability, Symbl.ai boasts a platform-agnostic design enabling seamless integration across various communication channels such as phone, web, social media, and more, providing a consistent conversational experience across different platforms, which is ideal for businesses with diverse communication needs. In contrast, Amazon Connect's Generative AI is tightly integrated with the Amazon Connect ecosystem, offering an advantage for users deeply embedded in the AWS infrastructure, but potentially limiting its versatility when integrating with non-AWS platforms or across multiple communication channels.

**Developer and User Community Support**
>>>>>>> 7d434583848d92fa524eb898610b1167ba63a9eb
Symbl.ai boasts extensive developer resources and support, facilitating easy implementation and customization according to specific requirements, alongside an active community and support forums that enable quick issue resolution and sharing of best practices. However, Amazon Connect's Generative AI, backed by the robust resources and support of AWS, is primarily focused on AWS-specific implementations, and its user community centers around AWS services, thereby limiting its exposure to broader conversational AI use cases. This makes Symbl.ai a more versatile and adaptable solution for diverse business needs.

While Amazon Connect's generative AI feature offers significant benefits for improving queue selection and customer interaction within the AWS ecosystem, Symbl.ai stands out with its specialized conversational intelligence capabilities, extensive customization options, real-time and post-conversation insights, and broader cross-platform support. For organizations looking to implement a more nuanced and flexible conversational AI solution that goes beyond the confines of queue selection, Symbl.ai presents a compelling choice.


<<<<<<< HEAD
Why provide call center agents with AI assistance in the first place? Any stats to support this need?

Call centers can be one of the most stressful work environments, with agents coping with problems of customers, strict schedules, linguistic and cultural barriers, highly variable workflows, multitasking, and repetitive tasks. Such concerns might lead to agent stress, burnout, and turnover. The high cost of replacing trained staff can discourage industrial managers and entrepreneurs who see high absenteeism, long waiting times, customer dissatisfaction, limited support, and high labor turnover of both customers, companies, and economies. Indeed, the way of communicating services to potential customers, the quality of services to existing customers, and the ways in which customer relationships are managed do have a big impact on the faithful customer base and growth of the business. The identification of the possible discomfort zones and the timely identification of the sense of humor, and courteous and professional words of the operators certainly support corporate image, helping the company in the communication activities and in improving its reputation. The capture of useful business information can also lead to further business activities.

Why Upgrade to AI-Assisted Systems?
1. Improved Customer Experience:

Transitioning to AI-assisted systems in contact centers is not just a trend but a necessity. A study by Accenture found that 57% of customers are willing to switch to a competitor after just one bad experience. Embracing this technology can help contact centers stay competitive and deliver exceptional service in an increasingly demanding marketplace by offering compelling solutions that can dynamically manage queues, significantly reduce wait times for customers by analyzing caller data in real-time and ensures calls are directed to the most suitable agent, enhancing the chances of a first-call resolution.

2. Enhanced Agent Performance:

According to a report by Salesforce, AI can boost agent productivity by up to 40%, allowing them to handle more queries efficiently. AI tools provide agents with instant access to customer information and recommended actions, enabling faster and more accurate responses. These automated systems handle routine inquiries and tasks, freeing up agents to focus on more complex issues. 

3. Operational Efficiency:

AI systems require less manual setup and management, reducing the risk of errors and the need for specialized expertise. Deloitte's research indicates that AI can reduce contact center costs by up to 20% by automating routine tasks and optimizing agent performance. This automation adjusts to changing call volumes without disrupting operations.


Solution Components and Purposes

Companies want to make sense of the conversations happening in their contact centers to improve productivity, gain insight, monitor quality, and react quickly to events as they unfold. There are many innovative technologies that are transforming the contact center, and below are some of the components and services leveraged for the sake of this tutorial and the purpose each of these services serve.

Amazon Connect: A cloud-based contact center solution that enables businesses to deliver superior customer service at a lower cost. This Amazon service will be used to handle customer calls and stream audio data to Amazon Kinesis.
Amazon Kinesis: A fully managed service that makes it easy to collect, process, and analyze real-time, streaming data. It will be used to stream audio data from Amazon Connect and process it for analysis.
Symbl.ai: A conversational intelligence platform that analyzes and generates insights from natural language conversations. It will be used to transcribe and analyze audio data, set up trackers, and implement Retrieval Augmented Generation (RAG) using Nebula LLM.
Nebula LLM: A large language model that generates human-like text based on input prompts. It will be used to generate answers to customer queries based on the knowledge base and similar content.


Prerequisites
=======
## Why provide call center agents with AI assistance in the first place? Any stats to support this need?

In an era of rapid technological advancements, many contact centers still rely on outdated queue selection mechanisms. These traditional systems, though once effective, now fall short in delivering the efficiency and flexibility required in today's fast-paced environment. These systems struggle to adapt to fluctuating call volumes, extended wait times, inflexible routing rules which often result in calls being directed to the wrong agents, frustrating customers and agents alike.

## Why Upgrade to AI-Assisted Systems?
**1. Improved Customer Experience:**
Transitioning to AI-assisted systems in contact centers is not just a trend but a necessity. A study by Accenture found that 57% of customers are willing to switch to a competitor after just one bad experience. Embracing this technology can help contact centers stay competitive and deliver exceptional service in an increasingly demanding marketplace by offering compelling solutions that can dynamically manage queues, significantly reduce wait times for customers by analyzing caller data in real-time and ensures calls are directed to the most suitable agent, enhancing the chances of a first-call resolution.

**2. Enhanced Agent Performance:**
According to a report by Salesforce, AI can boost agent productivity by up to 40%, allowing them to handle more queries efficiently. AI tools provide agents with instant access to customer information and recommended actions, enabling faster and more accurate responses. These automated systems handle routine inquiries and tasks, freeing up agents to focus on more complex issues. 

**3. Operational Efficiency:**
AI systems require less manual setup and management, reducing the risk of errors and the need for specialized expertise. Deloitte's research indicates that AI can reduce contact center costs by up to 20% by automating routine tasks and optimizing agent performance. This automation adjusts to changing call volumes without disrupting operations.

## What Software Were Leveraged For This Solution
The software used in this solution are:
Amazon Connect: A cloud-based contact center solution that enables businesses to deliver superior customer service at a lower cost. It will be used to handle customer calls and stream audio data to Amazon Kinesis.
Amazon Kinesis: A fully managed service that makes it easy to collect, process, and analyze real-time, streaming data. It will be used to stream audio data from Amazon Connect and process it for analysis.
Symbl.ai: A conversational intelligence platform that analyzes and generates insights from natural language conversations. It will be used to transcribe and analyze audio data, set up trackers, and implement Retrieval Augmented Generation (RAG) using Nebula LLM.
Nebula LLM: A large language model that generates human-like text based on input prompts. It will be used to generate answers to customer queries based on the knowledge base and similar content.
The purpose of this software is to create an AI assistant that provides real-time assistance to call center agents, enhancing their troubleshooting capabilities and improving customer satisfaction.

## Prerequisites
>>>>>>> 7d434583848d92fa524eb898610b1167ba63a9eb
You will need access to the following;

A pair of Access and Secret keys for the AWS account where Amazon Connect is configured.
A pair of appId and secret for Symbl.ai, which you can get from the platform’s main page. We use these to retrieve a temporary access token.
An API Key for Nebula LLM, which you get by joining the beta wait list.

<<<<<<< HEAD

Set up streaming for phone conversations

Streaming integration brings new opportunities to react to events as they happen, instead of waiting for transactions that process afterwards. Organizations who have realized this are using it for real-time analytics, machine learning, and other decision-making services. Here, you will learn about the use of the Amazon Connect (AC) and Amazon Kinesis (AK) services, extending to other Amazon features and Artificial Intelligence with Symbl.ai. API documentation details may change, but this article provides the basic ideas that help developers further explore and use these services.

Now to dive deep into the workings of this solution, we start by configuring all the neccessary credentials. 

Step 1: Set Up Amazon Connect
Create an Amazon Connect Instance:

Navigate to the Amazon Connect console.
Create a new Amazon Connect instance following the setup wizard.

Configure Contact Flows:
Go to the Amazon Connect dashboard.
Create or edit a contact flow to manage incoming calls.
Add a block to start streaming audio to Amazon Kinesis.

Step 2: Set Up Amazon Kinesis
Create a Kinesis Stream:

Go to the Amazon Kinesis console.
Create a new data stream and give it a name (e.g., ConnectAudioStream).
Set the number of shards based on your expected call volume.
Stream Data from Amazon Connect to Kinesis:

Modify the contact flow in Amazon Connect to add an AWS Lambda function that starts streaming audio to Kinesis.
Here’s the Lambda function to start streaming:

import boto3
import json

def lambda_handler(event, context):
    kinesis = boto3.client('kinesis')
    
    # Assuming 'Audio' is already base64 encoded in the event
    audio_data = event['Details']['ContactData']['MediaStreams']['Customer']['Audio']
    
    try:
        response = kinesis.put_record(
            StreamName='ConnectAudioStream',
            Data=audio_data,
            PartitionKey='partitionKey'
        )
        print("PutRecord Response: ", response)
        
        return {
            'statusCode': 200,
            'body': json.dumps('Audio streaming started')
        }
        
    except Exception as e:
        print("Error putting record into Kinesis: ", str(e))
        return {
            'statusCode': 500,
            'body': json.dumps('Error streaming audio')
        }



Use the Symbl.ai Telephony API
This section describes how to use the Symbl.ai Python SDK to open a connection, process an audio stream, and close a connection using the Telephony API.

Before You Begin
Ensure your developer environment meets the following requirements:

Download and install Python.

Create a new directory or folder for your Python project.

In the new directory, create a file named telephony.py.

On the command line, use pip to install the Python SDK:

pip3 install --upgrade symbl

Use the Telephony API
Create a new file in your script folder called telephony.py. The purpose of creating this file is to authorizes developers with the Telephony API and uses PSTN to call a given phone number. The sample also returns a conversation ID, which can be used to generate conversation intelligence.

import symbl

app_id = "<APP_ID>"
app_secret = "<APP_SECRET>"
phone_number = "<PHONE_NUMBER>"
email = "<EMAIL>"


connection_object = symbl.Telephony.start_pstn(
  credentials={"app_id": app_id, "app_secret": app_secret},
  phone_number=phone_number,
  actions = [
    {
      "invokeOn": "stop",
      "name": "sendSummaryEmail",
      "parameters": {
        "emails": [
          email
        ],
      },
    },
  ]
)

print("Conversation ID: " + connection_object.conversation.get_conversation_id())

Where:

<APP_ID> and <APP_SECRET> are your App ID and Secret from your Symbl.ai Home page.
<NAME> is the name of the person speaking.
<EMAIL> is the email address of the person speaking. If provided, when the audio stream ends, the Streaming API sends an email with conversation intelligence to the given address.
To run the code sample:

On the command line, go to your Python project directory.

Run the code sample.

python3 telephony.py
When you run the code, the Telephony API places a phone call to the given number and captures any spoken conversation.

Generate Conversational Intelligence:

Use the conversation ID obtained from the telephony.py file to retrieve messages and sentiment data from Symbl.ai.

import requests

base_url = "https://api.symbl.ai/v1/conversations/{conversation_id}/messages"
conversation_id = 'your_conversation_id'
=======
**Set up streaming for phone conversations**
Stream data out of Amazon Connect with Amazon Kinesis

**Step 1: Set up Amazon Connect**
Create an Amazon Connect instance

**Go to the Amazon Connect dashboard.**
Click on "Create instance" and follow the on-screen instructions to set up your instance.
Configure phone numbers and routing rules

In your Amazon Connect instance, navigate to "Routing" > "Phone numbers."
Claim a new number or use an existing one, then assign it to a contact flow.
Set up routing rules by creating contact flows in "Routing" > "Contact flows."
Enable call recording and storage in Amazon S3

Go to "Analytics" > "Contact Lens" and enable it.
Enable call recording in "Routing" > "Contact flows," and configure storage in Amazon S3.
Step 2: Create an Amazon Kinesis stream
Go to the Amazon Kinesis dashboard

Navigate to the Kinesis service in the AWS Management Console.
Click on "Create stream"

```aws kinesis create-stream --stream-name MyKinesisStream --shard-count 1```

Choose "Audio" as the stream type and configure settings

Set stream type to "Audio" (if applicable).
Configure settings like stream name (MyKinesisStream) and retention period.

Step 3: Configure Amazon Connect to stream data to Kinesis
Go to the Amazon Connect dashboard

Navigate to your Amazon Connect instance.
Click on "Settings" (gear icon)

Under "Data streaming," choose "Kinesis Stream."
Configure Kinesis stream details

```aws connect associate-kinesis-video-stream \
    --instance-id <your-connect-instance-id> \
    --stream-arn <kinesis-stream-arn> \
    --role-arn <iam-role-arn>
```

Enter the Kinesis stream name (MyKinesisStream) and region.
Configure additional settings like audio format and encryption.

Step 4: Test the streaming setup
Make a test call to your Amazon Connect phone number

Dial the number assigned to your Amazon Connect instance and speak for a few seconds.
Verify that the audio is being streamed to Kinesis

Use the Kinesis dashboard to view the incoming data stream.

```aws kinesis get-shard-iterator --stream-name MyKinesisStream --shard-id shardId-000000000000 --shard-iterator-type TRIM_HORIZON```

Step 5: Process and analyze the stream data
Use Amazon Kinesis Data Firehose to capture and process the stream data

Go to the Kinesis Data Firehose dashboard.
Create a new delivery stream and set the source to your Kinesis stream.

```aws firehose create-delivery-stream \
    --delivery-stream-name MyDeliveryStream \
    --kinesis-stream-source-configuration StreamARN=<kinesis-stream-arn>,RoleARN=<iam-role-arn>
```

Apply transformations and analytics using AWS Lambda

Create a Lambda function to process the data.
```import base64
import json
import boto3

def lambda_handler(event, context):
    for record in event['Records']:
        payload = base64.b64decode(record['kinesis']['data'])
        print("Decoded payload: " + str(payload))

    return {
        'statusCode': 200,
        'body': json.dumps('Hello from Lambda!')
    }
```


Configure the Kinesis stream to trigger the Lambda function.
Store the processed data in Amazon S3 or Amazon DynamoDB

Configure the Kinesis Data Firehose delivery stream to store data in S3 or DynamoDB
```aws firehose update-destination \
    --delivery-stream-name MyDeliveryStream \
    --current-delivery-stream-version-id <version-id> \
    --s3-destination-update RoleARN=<iam-role-arn>,BucketARN=<s3-bucket-arn>
```

Step 6: Integrate with Symbl.ai
Get an authentication token from Symbl.ai
```
import requests
import json

url = "https://api.symbl.ai/oauth2/token:generate"
payload = {
    "type": "application",
    "appId": "38716158656e6c4a4b725a7042695a5064477447386c733235644c346d487a62",
    "appSecret": "53474e38415266727a5f76526f6e797666674645497158506342586b4c47563541494d37716f2d6a79647a32546a43745f674767334c4576755377345a795630"
}
headers = {
    "Content-Type": "application/json"
}

response = requests.post(url, json=payload, headers=headers)
auth_token = response.json()['accessToken']
print("Auth Token:", auth_token)
```


Transcribe audio for conversational intelligence
Use the Symbl.ai streaming/telephony API

Transcribe and analyze the audio data using Symbl.ai API

To generate a transcription and intelligence from both audio and text data using the Symbl.ai API, you can follow these steps:

1. Generate Access Token
First, authenticate to get the access token. This token will be used for all subsequent API calls.

Request:
```
import requests
import json

url = "https://api.symbl.ai/oauth2/token:generate"

appId = "38716158656e6c4a4b725a7042695a5064477447386c733235644c346d487a62"
appSecret = "53474e38415266727a5f76526f6e797666674645497158506342586b4c47563541494d37716f2d6a79647a32546a43745f674767334c4576755377345a795630"

payload = {
    "type": "application",
    "appId": appId,
    "appSecret": appSecret
}
headers = {
    'Content-Type': 'application/json'
}

response = requests.post(url, headers=headers, data=json.dumps(payload))

if response.status_code == 200:
    access_token = response.json()['accessToken']
    print("accessToken => " + access_token)
else:
    print("Failed to get access token", response.text)
```


2. Process Audio or Text Data
Now, use the access token to process your audio or text data. For this example, we will process an audio file.

```
import requests
import json

url = "https://api.symbl.ai/v1/process/audio/url"
access_token = 'your_access_token'  # Replace with the access token from the previous step

headers = {
    'Authorization': 'Bearer ' + access_token,
    'Content-Type': 'application/json'
}

payload = {
  "url": "https://symbltestdata.s3.us-east-2.amazonaws.com/newPhonecall.mp3",
  "name": "Test Conversation",
  "languageCode": "en-US"
}

response = requests.post(url, headers=headers, data=json.dumps(payload))

if response.status_code == 201:
    conversation_id = response.json()['conversationId']
    job_id = response.json()['jobId']
    print("conversationId => " + conversation_id)
    print("jobId => " + job_id)
else:
    print("Failed to process audio", response.text)
```



3. Check Job Status
Check the status of the job to ensure it is completed.

Request:
```
import requests

url = f'https://api.symbl.ai/v1/job/{job_id}'
access_token = 'your_access_token'

headers = {
    'Authorization': 'Bearer ' + access_token,
    'Content-Type': 'application/json'
}

response = requests.get(url, headers=headers)

if response.status_code == 200:
    job_status = response.json()['status']
    print("Job Status => " + job_status)
else:
    print("Failed to get job status", response.text)
```


4. Retrieve Messages with Intelligence
Finally, retrieve the messages from the conversation and include sentiment analysis.

Request:
```
import requests

base_url = "https://api.symbl.ai/v1/conversations/{conversation_id}/messages"
conversation_id = 'your_conversation_id'  # Replace with the conversationId obtained earlier
>>>>>>> 7d434583848d92fa524eb898610b1167ba63a9eb
access_token = 'your_access_token'

url = base_url.format(conversation_id=conversation_id)

headers = {
    'Authorization': 'Bearer ' + access_token,
    'Content-Type': 'application/json'
}

params = {
    'verbose': True, 
    'sentiment': True 
}

response = requests.get(url, headers=headers, params=params)

if response.status_code == 200:
    messages = response.json()['messages']
    for message in messages:
        print(f"Message ID: {message['id']}")
        print(f"Text: {message['text']}")
        print(f"Sentiment: {message['sentiment']['polarity']['score']}")
        print("------")
else:
    print("Failed to get messages", response.text)
<<<<<<< HEAD



Determine When Call Center Agents Receive AI Assistance
To determine when agents can receive real-time AI assistance during remote troubleshooting calls, you need to create trackers and configure triggers that activate the running of the created tracker. In this section, we will configure trackers on Symbl.ai using common troubleshooting phrases as triggers.

Step-by-Step Guide
Set Up Trackers with Symbl.ai

Login to Symbl.ai:

Go to the Symbl.ai website and log in to your account. You will be directed to the Symbl.ai dashboard.
Create a Custom Tracker:

Navigate to Tracker Management.
Click on Create Custom Tracker.
Configure the Custom Tracker:

You will be directed to a page where you need to fill in the following fields:
Tracker Name: Provide a name for the tracker.
Description: Describe the purpose of the tracker.
Categories: Choose "Contact Center" as the category.
Language: Select the language for the tracker.
Vocabulary: Add at least four phrases that will serve as troubleshooting triggers. For example, "restart", "reboot", "reset", "troubleshoot", "error", and "not working".

View the Tracker:
After creating the custom tracker, go to the API Explorer and click on Trackers to see the newly created tracker

Example Troubleshooting Triggers:
```trackers = [
    {
        "name": "Troubleshooting",
        "vocabulary": ["restart", "reboot", "reset", "troubleshoot", "error", "not working"]
    }
]```

By following these steps, you can effectively determine when call center agents receive AI assistance using Symbl.ai. Setting up trackers with specific troubleshooting phrases ensures that AI assistance is provided at the right moments, enhancing the efficiency and effectiveness of your call center operations.


Provide Agents with real-time AI assistance
It is time to put all that have been discussed into an actionable real-time perspective by providing a practical walk-through of a sample use case that provide an agent wuth real-time assistance during a conversation with a client. At this point in this tutorial, it is assumed that you have created an account on the Symbl.ai platform, and have access to Nebula LLM and have completed the necessary authentication. If you require assistance on any of these steps, refer to our docs on getting started and how to authenticate. If you need access to the Nebula Playground and model API visit https://symbl.ai.


Implementing Real-Time AI Assistance
Here's how you can incorporate Amazon Connect, Amazon Kinesis, and Nebula LLM in the workflow:

Configure Amazon Connect and Kinesis Stream:

```import boto3

# Create a Kinesis client
kinesis_client = boto3.client('kinesis')

# Create a Kinesis stream
response = kinesis_client.create_stream(
    StreamName='YourKinesisStreamName',
    ShardCount=1
)```

Set Up Kinesis Stream to Receive Audio Data from Amazon Connect:
In the Amazon Connect console, configure the instance to stream call audio data to the Kinesis stream created above.

Read from Kinesis Stream and Send to Symbl.ai:

```import boto3
import requests
import json

# Initialize the Kinesis client
kinesis_client = boto3.client('kinesis')

# Function to read data from Kinesis stream
def read_from_kinesis():
    response = kinesis_client.get_shard_iterator(
        StreamName='YourKinesisStreamName',
        ShardId='shardId-000000000000',
        ShardIteratorType='LATEST'
    )

    shard_iterator = response['ShardIterator']
    records_response = kinesis_client.get_records(ShardIterator=shard_iterator, Limit=10)

    for record in records_response['Records']:
        audio_chunk = record['Data']  # Extract the audio chunk

        # Send audio data to Symbl.ai for transcription
        symbl_response = requests.post(
            "https://api.symbl.ai/v1/process/audio",
            headers={
                'Authorization': 'Bearer ' + symbl_api_key,
                'Content-Type': 'application/json'
            },
            data=json.dumps({
                'audio_url': 's3://your-audio-file-path'
            })
        )

        transcription = symbl_response.json()
        print(transcription)  # Print or process the transcription

        # Send transcription to Nebula LLM for real-time assistance
        assist_agent(transcription)

def assist_agent(transcription):
    url = "https://api-nebula.symbl.ai/v1/model/chat/streaming"
    payload = json.dumps({
        "max_new_tokens": 1024,
        "system_prompt": "You are a service support assistant. You help users troubleshoot issues with purchased products and services. You are respectful, professional and you always respond politely.",
        "messages": [
            {
                "role": "human",
                "text": transcription['text']
            }
        ]
    })
    headers = {
        'ApiKey': NEBULA_API_KEY,
        'Content-Type': 'application/json'
    }

    response = requests.request("POST", url, headers=headers, data=payload)
    print(response.json())  # Real-time AI assistance response

# Continuously read from Kinesis stream
while True:
    read_from_kinesis()```


This script demonstrates the end-to-end process of streaming audio data from Amazon Connect via Amazon Kinesis, transcribing it using Symbl.ai, and providing real-time AI assistance with Nebula LLM.

By integrating Amazon Connect and Amazon Kinesis with Symbl.ai and Nebula LLM, you can create a robust system for real-time AI assistance in your call center. This setup ensures that agents receive immediate support upon the trigger of troubleshooting phrases during customer interactions, improving efficiency and customer satisfaction.

Implement retrieval augmented generation (RAG) with call center training materials
To implement retrieval augmented generation (RAG) with call center training materials using the Nebula API, you'll need to adapt the provided code snippet. RAG is a technique that combines retrieval-based and generation-based methods, which typically involves fetching relevant documents or pieces of information to help generate a more informed and accurate response.

Step-by-Step Implementation
Step 1: Setup
Ensure you have your API key and the necessary endpoint URLs.

Step 2: Retrieve Relevant Information

```import torch
from transformers import BartForConditionalGeneration, BartTokenizer
from elasticsearch import Elasticsearch
import requests
import json

# Initialize Elasticsearch client
es = Elasticsearch()

# Initialize BART model and tokenizer
model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')
tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')

# Symbl.ai API key and URL
SYMBL_API_KEY = 'YOUR_SYMBL_API_KEY'
SYMBL_URL_TRACKER = 'https://api.symbl.ai/v1/process/text'

def symbl_extract_context(query):
    headers = {
        'Authorization': f'Bearer {SYMBL_API_KEY}',
        'Content-Type': 'application/json'
    }
    payload = {
        'messages': [{'payload': {'content': query, 'contentType': 'text/plain'}}]
    }
    response = requests.post(SYMBL_URL_TRACKER, headers=headers, data=json.dumps(payload))
    response_data = response.json()

    # Extract key phrases and topics from Symbl.ai response
    key_phrases = [phrase['text'] for phrase in response_data.get('context', {}).get('keyPhrases', [])]
    topics = [topic['text'] for topic in response_data.get('context', {}).get('topics', [])]
    
    # Extract matched phrases from tracker
    trackers = response_data.get('trackers', {}).get('matches', [])
    matched_phrases = [match['text'] for match in trackers]

    # Combine key phrases, topics, and matched phrases for enhanced retrieval
    context_terms = key_phrases + topics + matched_phrases
    return ' '.join(context_terms)

def retrieve_training_materials(query):
    # Enhance query with context extraction using Symbl.ai
    enhanced_query = symbl_extract_context(query)
    
    # Search for relevant documents in Elasticsearch
    search_response = es.search(index='knowledge_base', body={'query': {'match': {'content': enhanced_query}}})
    relevant_docs = [hit['_source']['content'] for hit in search_response['hits']['hits']]
    return relevant_docs

def generate_response(query, context):
    # Combine the query with retrieved context
    combined_input = query + " " + " ".join(context)
    
    # Tokenize the combined input
    input_ids = tokenizer.encode(combined_input, return_tensors='pt', truncation=True, max_length=1024)
    
    # Generate the response
    output = model.generate(input_ids=input_ids, max_length=150, num_return_sequences=1)
    response = tokenizer.decode(output[0], skip_special_tokens=True)
    
    return response

def rag(query):
    # Retrieve relevant documents
    relevant_docs = retrieve_training_materials(query)
    
    # Generate response with context
    response = generate_response(query, relevant_docs)
    
    return response```

# Test the RAG model
query = 'How do I troubleshoot a slow computer?'
response = rag(query)
print(response)

In the code above, Symbl.ai's tracking API was leveraged to check if the query contains any of the predefined key phrases and vocabulary. You can integrate this check into your system to enhance the query before passing it to Elasticsearch for document retrieval.

Explanation
Symbl.ai Trackers API:
symbl_extract_context includes logic to call Symbl.ai’s tracker API and extract matches from the predefined tracker.
The payload for the Symbl.ai API call remains the same, but the response handling now checks for tracker matches in the trackers section of the response.

Enhanced Query:
This function combines key phrases, topics, and matched phrases from the tracker to form a more comprehensive enhanced query.

Document Retrieval:
Elasticsearch uses the enhanced query to search for relevant documents.
By using the existing tracker on Symbl.ai, the RAG system becomes more efficient in identifying relevant phrases and topics, thus improving the overall accuracy and relevance of the generated responses.

Set up a simple agent assist chatbot
To set up a simple agent assist chatbot that uses retrieval-augmented generation (RAG) with Elasticsearch and BART, integrated with Symbl.ai for context extraction and trackers, you can follow the steps below. This example includes the necessary code to build a basic chatbot using these components.

** Requirements **
Install the required libraries:
pip install torch transformers elasticsearch requests

Ensure you have an Elasticsearch instance running and Symbl.ai API access with your API key.

** Code Implementation **
Here is the complete implementation of a simple agent assist chatbot:

```import torch
from transformers import BartForConditionalGeneration, BartTokenizer
from elasticsearch import Elasticsearch
import requests
import json

# Initialize Elasticsearch client
es = Elasticsearch()

# Initialize BART model and tokenizer
model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')
tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')

# Symbl.ai API key and URL
SYMBL_API_KEY = 'YOUR_SYMBL_API_KEY'
SYMBL_URL_TRACKER = 'https://api.symbl.ai/v1/process/text'

# Function to extract context using Symbl.ai
def symbl_extract_context(query):
    headers = {
        'Authorization': f'Bearer {SYMBL_API_KEY}',
        'Content-Type': 'application/json'
    }
    payload = {
        'messages': [{'payload': {'content': query, 'contentType': 'text/plain'}}]
    }
    response = requests.post(SYMBL_URL_TRACKER, headers=headers, data=json.dumps(payload))
    response_data = response.json()

    # Extract key phrases, topics, and matched phrases from Symbl.ai response
    key_phrases = [phrase['text'] for phrase in response_data.get('context', {}).get('keyPhrases', [])]
    topics = [topic['text'] for topic in response_data.get('context', {}).get('topics', [])]
    trackers = response_data.get('trackers', {}).get('matches', [])
    matched_phrases = [match['text'] for match in trackers]

    # Combine key phrases, topics, and matched phrases for enhanced retrieval
    context_terms = key_phrases + topics + matched_phrases
    return ' '.join(context_terms)

# Function to retrieve relevant documents from Elasticsearch
def retrieve_training_materials(query):
    # Enhance query with context extraction using Symbl.ai
    enhanced_query = symbl_extract_context(query)
    
    # Search for relevant documents in Elasticsearch
    search_response = es.search(index='knowledge_base', body={'query': {'match': {'content': enhanced_query}}})
    relevant_docs = [hit['_source']['content'] for hit in search_response['hits']['hits']]
    return relevant_docs

# Function to generate response using BART model
def generate_response(query, context):
    # Combine the query with retrieved context
    combined_input = query + " " + " ".join(context)
    
    # Tokenize the combined input
    input_ids = tokenizer.encode(combined_input, return_tensors='pt', truncation=True, max_length=1024)
    
    # Generate the response
    output = model.generate(input_ids=input_ids, max_length=150, num_return_sequences=1)
    response = tokenizer.decode(output[0], skip_special_tokens=True)
    
    return response

# Function to handle RAG process
def rag(query):
    # Retrieve relevant documents
    relevant_docs = retrieve_training_materials(query)
    
    # Generate response with context
    response = generate_response(query, relevant_docs)
    
    return response

# Main function to run the chatbot
def main():
    print("Welcome to the Agent Assist Chatbot!")
    while True:
        user_query = input("You: ")
        if user_query.lower() in ['exit', 'quit']:
            print("Goodbye!")
            break
        response = rag(user_query)
        print(f"Bot: {response}")

# Run the chatbot
if __name__ == "__main__":
    main()```

Explanation
Initialize Components:

Elasticsearch client to retrieve documents.
BART model and tokenizer for generating responses.
Symbl.ai API key and URL for context extraction.
Symbl.ai Context Extraction:

symbl_extract_context function sends the query to Symbl.ai to extract key phrases, topics, and matched phrases from the predefined tracker.

Document Retrieval:
retrieve_training_materials function uses the enhanced query to search for relevant documents in Elasticsearch.

** Response Generation **:

generate_response function combines the user query with the retrieved documents' content and generates a response using the BART model.

RAG Process:
rag function integrates document retrieval and response generation to provide a coherent answer to the user's query.

Chatbot Interaction:
main function handles the user interaction in a loop, continuously processing user queries and providing responses until the user decides to exit.
This setup provides a basic agent assist chatbot that leverages retrieval-augmented generation to provide informed and contextually relevant responses to user queries.


In this tutorial, we successfully built a simple agent assist chatbot using Retrieval-Augmented Generation (RAG) with Elasticsearch and BART, enhanced by Symbl.ai's context extraction capabilities. This chatbot can significantly aid call center agents by providing quick, contextually relevant responses to customer inquiries, thus improving response times and accuracy. Customers benefit from receiving precise and helpful information swiftly, leading to a better overall experience and increased satisfaction.

To take this solution further, consider integrating advanced features such as multi-turn conversation handling to maintain context across multiple interactions. Additionally, incorporating sentiment analysis could help agents prioritize and tailor their responses based on the customer's emotional state. Another improvement could be using more sophisticated models like GPT-4 for enhanced language understanding and response generation. Finally, expanding the knowledge base in Elasticsearch with a wider array of documents and regularly updating it with new information can ensure that the chatbot remains relevant and accurate.












=======
```


Example Response
A successful response for the messages request might look like this:
```
{
    "messages": [
        {
            "id": "5286731529191424",
            "text": "I installed your internet service for my new home and it's really slow.",
            "from": {
                "id": "36af93d9-319c-4621-911b-574ce1f7007b",
                "name": "Speaker 1"
            },
            "startTime": "2024-05-24T15:24:47.721Z",
            "endTime": "2024-05-24T15:24:50.321Z",
            "timeOffset": 5.4,
            "duration": 2.6,
            "conversationId": "6246804023803904",
            "phrases": [],
            "sentiment": {
                "polarity": {
                    "score": -0.953
                },
                "suggested": "negative"
            },
            "words": [
                {
                    "word": "I",
                    "startTime": "2024-05-24T15:24:47.721Z",
                    "endTime": "2024-05-24T15:24:48.121Z",
                    "speakerTag": 1,
                    "score": 0.87,
                    "timeOffset": 5.4,
                    "duration": 0.4
                },
                {
                    "word": "installed",
                    "startTime": "2024-05-24T15:24:48.121Z",
                    "endTime": "2024-05-24T15:24:48.221Z",
                    "speakerTag": 1,
                    "score": 0.96,
                    "timeOffset": 5.8,
                    "duration": 0.1
                },
                {
                    "word": "your",
                    "startTime": "2024-05-24T15:24:48.221Z",
                    "endTime": "2024-05-24T15:24:48.321Z",
                    "speakerTag": 1,
                    "score": 0.99,
                    "timeOffset": 5.9,
                    "duration": 0.1
                },
                {
                    "word": "internet",
                    "startTime": "2024-05-24T15:24:48.321Z",
                    "endTime": "2024-05-24T15:24:48.721Z",
                    "speakerTag": 1,
                    "score": 0.99,
                    "timeOffset": 6,
                    "duration": 0.4
                },
                {
                    "word": "service",
                    "startTime": "2024-05-24T15:24:48.721Z",
                    "endTime": "2024-05-24T15:24:49.021Z",
                    "speakerTag": 1,
                    "score": 0.99,
                    "timeOffset": 6.4,
                    "duration": 0.3
                },
                {
                    "word": "for",
                    "startTime": "2024-05-24T15:24:49.021Z",
                    "endTime": "2024-05-24T15:24:49.121Z",
                    "speakerTag": 1,
                    "score": 0.97,
                    "timeOffset": 6.7,
                    "duration": 0.1
                },
                {
                    "word": "my",
                    "startTime": "2024-05-24T15:24:49.121Z",
                    "endTime": "2024-05-24T15:24:49.321Z",
                    "speakerTag": 1,
                    "score": 1,
                    "timeOffset": 6.8,
                    "duration": 0.2
                },
                {
                    "word": "new",
                    "startTime": "2024-05-24T15:24:49.321Z",
                    "endTime": "2024-05-24T15:24:49.421Z",
                    "speakerTag": 1,
                    "score": 1,
                    "timeOffset": 7,
                    "duration": 0.1
                },
                {
                    "word": "home",
                    "startTime": "2024-05-24T15:24:49.421Z",
                    "endTime": "2024-05-24T15:24:49.621Z",
                    "speakerTag": 1,
                    "score": 1,
                    "timeOffset": 7.1,
                    "duration": 0.2
                },
                {
                    "word": "and",
                    "startTime": "2024-05-24T15:24:49.621Z",
                    "endTime": "2024-05-24T15:24:49.721Z",
                    "speakerTag": 1,
                    "score": 0.97,
                    "timeOffset": 7.3,
                    "duration": 0.1
                },
                {
                    "word": "it's",
                    "startTime": "2024-05-24T15:24:49.721Z",
                    "endTime": "2024-05-24T15:24:49.921Z",
                    "speakerTag": 1,
                    "score": 0.96,
                    "timeOffset": 7.4,
                    "duration": 0.2
                },
                {
                    "word": "really",
                    "startTime": "2024-05-24T15:24:49.921Z",
                    "endTime": "2024-05-24T15:24:50.021Z",
                    "speakerTag": 1,
                    "score": 1,
                    "timeOffset": 7.6,
                    "duration": 0.1
                },
                {
                    "word": "slow.",
                    "startTime": "2024-05-24T15:24:50.021Z",
                    "endTime": "2024-05-24T15:24:50.321Z",
                    "speakerTag": 1,
                    "score": 1,
                    "timeOffset": 7.7,
                    "duration": 0.3
                }
            ]
        }
    ]
}
```


This guide provides a comprehensive overview, from setting up Amazon Connect and Kinesis to integrating with Symbl.ai for advanced conversation analytics. For detailed instructions and best practices, refer to the AWS documentation and Symbl.ai API documentation.

## Determine when call center agents receive AI assistance
To determine when call center agents receive AI assistance using Symbl.ai, you can set up trackers that use common phrases in troubleshooting calls as triggers. Here’s a detailed step-by-step guide based on your provided information:

Determine when call center agents receive AI assistance
Call center agents can receive AI assistance in various situations, such as:
Difficult customer interactions: AI can provide real-time sentiment analysis and suggest responses to de-escalate tensions.
Complex troubleshooting: AI can offer step-by-step guides and potential solutions based on similar cases.
Long call duration: AI can suggest ways to wrap up the call efficiently while ensuring customer satisfaction.
New agent training: AI can provide real-time feedback and coaching to new agents during calls.


## Set up trackers with Symbl.ai
To set up trackers with Symbl.ai, follow these steps:
Identify key phrases: Determine common phrases and keywords related to troubleshooting calls, such as "technical issue," "error message," or "product malfunction."

**Create trackers:** Use Symbl.ai's Tracker API to create custom trackers for these key phrases. This will enable real-time detection and notification when these phrases are spoken during calls.

**Configure notifications:** Set up notifications to alert agents or supervisors when a tracker is triggered. This can be done through Symbl.ai's Webhook API or integrations with other tools.

**Integrate with call center software:** Integrate Symbl.ai's trackers with your call center software to enable real-time tracking and notification during calls.

Use common phrases for troubleshooting calls as triggers
Some common phrases that can be used as triggers for AI assistance in troubleshooting calls include:
"I'm having a problem with..."
"I'm getting an error message..."
"My [product/service] is not working..."
"I've tried [solution] but it didn't work..."
"Can you help me troubleshoot...?"

When these phrases are spoken during a call, Symbl.ai's trackers can trigger AI assistance, such as:
Real-time sentiment analysis: Provide agents with sentiment analysis to understand the customer's emotional state.
Troubleshooting guides: Offer step-by-step guides and potential solutions based on similar cases.
Product information: Provide agents with relevant product information and specifications.
Solution suggestions: Suggest potential solutions based on the customer's issue.

By setting up trackers with Symbl.ai and using common phrases for troubleshooting calls as triggers, call center agents can receive timely AI assistance to resolve customer issues efficiently and effectively.


**Set up trackers with Symbl.ai**
Generate an Access Token: This token is required to authenticate your API requests to Symbl.ai.
```
curl -k -X POST "https://api.symbl.ai/oauth2/token:generate" \
     --header "accept: application/json" \
     --header "Content-Type: application/json" \
     -d '{
      "type" : "application",
      "appId": "YOUR_APP_ID",
      "appSecret": "YOUR_APP_SECRET"
    }'
```

Replace YOUR_APP_ID and YOUR_APP_SECRET with your actual Symbl.ai credentials. The response will include an accessToken.

Process the Audio Conversation: This involves sending the audio file to Symbl.ai for processing.
```
curl --location --request POST "https://api.symbl.ai/v1/process/audio/url" \
--header "Content-Type: application/json" \
--header "Authorization: Bearer YOUR_ACCESS_TOKEN" \
--data-raw '{
  "url": "https://symbltestdata.s3.us-east-2.amazonaws.com/newPhonecall.mp3",
  "name": "Phone Call Analysis",
  "languageCode": "en-US"
}'
```
Replace YOUR_ACCESS_TOKEN with the token you received earlier. The response will include conversationId and jobId.

Check the Job Status: Ensure the job has been completed before proceeding.
```
curl --location --request GET "https://api.symbl.ai/v1/job/YOUR_JOB_ID" \
--header 'Content-Type: application/json' \
--header "Authorization: Bearer YOUR_ACCESS_TOKEN"
```

Replace YOUR_JOB_ID with the job ID from the previous step. Wait until the job status is completed.

Set Up Trackers: Create trackers with common troubleshooting phrases as triggers.

```
curl "https://api.symbl.ai/v1/conversations/YOUR_CONVERSATION_ID/trackers" \
    --header "Authorization: Bearer YOUR_ACCESS_TOKEN" \
    --data-raw '{
      "trackers": [
        {
          "name": "Troubleshooting",
          "vocabulary": ["restart", "reboot", "reset", "troubleshoot", "error", "not working"]
        }
      ]
    }'
```

Replace YOUR_CONVERSATION_ID with the conversation ID from the processing step. Adjust the vocabulary list with phrases relevant to your troubleshooting scenarios.

Retrieve Tracker Matches: Fetch the matches for the defined trackers to see where these phrases were used in the conversation.
```
curl "https://api.symbl.ai/v1/conversations/YOUR_CONVERSATION_ID/trackers" \
    --header "Authorization: Bearer YOUR_ACCESS_TOKEN"
```
The response will include a list of trackers and the phrases that were matched, along with their occurrences in the conversation.

Example Scenario
After running these steps, you might get a response like this:
```
[
    {
        "id": "4712249169149952",
        "name": "Troubleshooting",
        "matches": [
            {
                "type": "vocabulary",
                "value": "restart",
                "messageRefs": [
                    {
                        "id": "5192198242041856",
                        "text": "Can you please restart your device?",
                        "offset": -1
                    }
                ],
                "insightRefs": []
            },
            {
                "type": "vocabulary",
                "value": "error",
                "messageRefs": [
                    {
                        "id": "5613607799881728",
                        "text": "Are you seeing any error messages?",
                        "offset": -1
                    }
                ],
                "insightRefs": []
            }
        ]
    }
]
```

This output indicates that the phrases "restart" and "error" were used during the call, triggering the "Troubleshooting" tracker. Using this information, you can identify specific points in the call where the agent provided troubleshooting assistance.


Here is a step-by-step guide to building a real-time agent assist chatbot using Nebula LLM and RAG with a Python SDK:

Step 1: Install Python SDK
Install the Symbl AI Python SDK using pip: pip install symbl-ai

Step 2: Set up API Access
Import the SDK and set up API access using your AppId and AppSecret:

from symbl_ai import Symbl

symbl = Symbl(app_id='YOUR_APP_ID', app_secret='YOUR_APP_SECRET')
>>>>>>> 7d434583848d92fa524eb898610b1167ba63a9eb
