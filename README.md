# Real-Time AI Assistance for Call Center Agents
Conversational AI is currently attracting great attention in various industries such as smart home, customer service, and especially automated call centers. Traditional call center systems require significant workforces to handle customer inquiries, resulting in increased companies' operation costs. Many companies have sought to automate call centers by implementing their own customized interactive voice response systems or benefiting from one of the various commercial, off-the-shelf systems. However, these traditional conversational agents have several limitations. These agents typically require a well-structured interaction design and strictly processed user input. For example, if the users do not select the appropriate number or manually input information about their identities and intentions, traditional call center agents would be difficult to properly understand and help solve the users' inquiries. This results in a high customer churn rate. Furthermore, traditional conversational agents implement scripted and flow-guided dialogs, which makes agents straightforward. Given the ever-growing customer service terrain, call center agents of today need efficient tools in order to be able to tackle issues quicker and with better results. The crux of much of this growing needs lie more in situation when those that need help and or want to know more about what you have available, reach out with questions or ask for assistance. This moment, right here is when a relationship with the customer either blooms or wilts. Unfortunately for many contact centers, they suffer from an onerous and antiquated queue mechanism that results in excessive chances to wait in a long line only to be evenly distributed across limited seats. Overall this traditional process can be revolutionized by integrating artificial intelligence components such as generative models like Nebula LLM of Symbl AI into platforms such as Amazon Connect powered by services like Amazon Kinesis. ⁤ ⁤
Bearing in mind the need to assist contact center agents with real-time intelligent assistance, this tutorial explains steps to integrate asynchronous Amazon Connect with Symbl calls to enhance its real-time speech to text capabilities and transform call centers. The architecture follows a serverless design, thus minimizing the need to support physical on-premise infrastructure. By implementing this solution, technical architects can save additional development skills, including telephony and machine learning, to focus on custom business use-case requirements. This provides a great way to transform call centers faster and create meaningful experiences for agents and a more reliable and secure environment for organizations.

**Why Use Symbl.ai Over Amazon Connect's Generative AI Feature?**
As a relatively young market with multiple players, contact centers can sometimes find it challenging to choose a specific technology to satisfy their needs. In this section of the tutorial, we will provide developers an extensive comparative analysis of the two technologies (Symbl.ai and Amazon Connect Generative AI) often used by Contact Centers to help businesses make a more informed decision and why we have a more favored inclination towards Symbl.ai when it comes to providing real-time assistance to contact center agents. We study the AI-powered Symbl.ai technology, which is a cloud-based API platform for processing conversation data, and the Amazon Connect technology, which is a cloud service that enables businesses to automate and improve the customer experience they deliver to their customers. Below is an elaborate explanation from different thematic concerns to futher understand why you should use Symbl.ai Over Amazon Connect's Generative AI Feature.

**Specialized Conversational Intelligence**
Symbl.ai specializes in advanced conversational intelligence, offering capabilities that go beyond simple generative responses and real-time transcription. Its features, such as sentiment analysis, topic extraction, conversation summarization, action item detection, and follow-up tracking, provide a deeper understanding of customer interactions and enhance agent productivity. In contrast, Amazon Connect's Generative AI primarily focuses on streamlining queue selection and handling natural language inputs, making it effective for improving queue selection through natural language descriptions, but lacking the same depth of conversational analysis as Symbl.ai.

**Real-Time and Post-Conversation Insights**
With comprehensive analytics suite offerings, Symbl.ai provides both real-time and post-conversation insights, which are essential for immediate customer support and long-term strategic planning. Its real-time capabilities, including live transcription and contextual understanding, significantly enhance agent performance and customer satisfaction. Amazon Connect's Generative AI, on the other hand, primarily focuses on improving the customer interaction process during the call, particularly in queue selection, but may lack the comprehensive post-conversation insights offered by Symbl.ai, limiting its utility for ongoing improvements and strategic analysis.

**Scalability and Cross-Platform Support**

In terms of flexibility and adaptability, Symbl.ai boasts a platform-agnostic design enabling seamless integration across various communication channels such as phone, web, social media, and more, providing a consistent conversational experience across different platforms, which is ideal for businesses with diverse communication needs. In contrast, Amazon Connect's Generative AI is tightly integrated with the Amazon Connect ecosystem, offering an advantage for users deeply embedded in the AWS infrastructure, but potentially limiting its versatility when integrating with non-AWS platforms or across multiple communication channels.

**Developer and User Community Support**

Symbl.ai boasts extensive developer resources and support, facilitating easy implementation and customization according to specific requirements, alongside an active community and support forums that enable quick issue resolution and sharing of best practices. However, Amazon Connect's Generative AI, backed by the robust resources and support of AWS, is primarily focused on AWS-specific implementations, and its user community centers around AWS services, thereby limiting its exposure to broader conversational AI use cases. This makes Symbl.ai a more versatile and adaptable solution for diverse business needs.

## Real-Time AI Assistance for Call Center Agents ##
In today's fast-paced customer service landscape, call center agents need efficient tools to resolve issues quickly and effectively. This tutorial will guide developers in integrating Amazon Connect and Symbl.ai using Amazon Kinesis to create an AI assistant with Symbl.ai Trackers and Nebula LLM. This solution aims to provide call center agents with real-time AI assistance, enhancing their troubleshooting capabilities and improving customer satisfaction.

## Why Use Symbl.ai Over Amazon Connect's Generative AI Feature? ##
When comparing Symbl.ai to Amazon Connect's generative AI feature for transforming contact center experiences, there are several distinct advantages that Symbl.ai offers, particularly in terms of flexibility, depth of integration, and specialized capabilities. Here’s a detailed look at why you might choose Symbl.ai over Amazon Connect's generative AI:

**Specialized Conversational Intelligence**

Symbl.ai specializes in advanced conversational intelligence, offering capabilities that go beyond simple generative responses and real-time transcription. Its features, such as sentiment analysis, topic extraction, conversation summarization, action item detection, and follow-up tracking, provide a deeper understanding of customer interactions and enhance agent productivity. In contrast, Amazon Connect's Generative AI primarily focuses on streamlining queue selection and handling natural language inputs, making it effective for improving queue selection through natural language descriptions, but lacking the same depth of conversational analysis as Symbl.ai.

**Real-Time and Post-Conversation Insights**

With comprehensive analytics suite offerings, Symbl.ai provides both real-time and post-conversation insights, which are essential for immediate customer support and long-term strategic planning. Its real-time capabilities, including live transcription and contextual understanding, significantly enhance agent performance and customer satisfaction. Amazon Connect's Generative AI, on the other hand, primarily focuses on improving the customer interaction process during the call, particularly in queue selection, but may lack the comprehensive post-conversation insights offered by Symbl.ai, limiting its utility for ongoing improvements and strategic analysis.

**Scalability and Cross-Platform Support**

In terms of flexibility and adaptability, Symbl.ai boasts a platform-agnostic design enabling seamless integration across various communication channels such as phone, web, social media, and more, providing a consistent conversational experience across different platforms, which is ideal for businesses with diverse communication needs. In contrast, Amazon Connect's Generative AI is tightly integrated with the Amazon Connect ecosystem, offering an advantage for users deeply embedded in the AWS infrastructure, but potentially limiting its versatility when integrating with non-AWS platforms or across multiple communication channels.

**Developer and User Community Support**

Symbl.ai boasts extensive developer resources and support, facilitating easy implementation and customization according to specific requirements, alongside an active community and support forums that enable quick issue resolution and sharing of best practices. However, Amazon Connect's Generative AI, backed by the robust resources and support of AWS, is primarily focused on AWS-specific implementations, and its user community centers around AWS services, thereby limiting its exposure to broader conversational AI use cases. This makes Symbl.ai a more versatile and adaptable solution for diverse business needs.

While Amazon Connect's generative AI feature offers significant benefits for improving queue selection and customer interaction within the AWS ecosystem, Symbl.ai stands out with its specialized conversational intelligence capabilities, extensive customization options, real-time and post-conversation insights, and broader cross-platform support. For organizations looking to implement a more nuanced and flexible conversational AI solution that goes beyond the confines of queue selection, Symbl.ai presents a compelling choice.

**Why provide call center agents with AI assistance in the first place? Any stats to support this need

Call centers can be one of the most stressful work environments, with agents coping with problems of customers, strict schedules, linguistic and cultural barriers, highly variable workflows, multitasking, and repetitive tasks. Such concerns might lead to agent stress, burnout, and turnover. The high cost of replacing trained staff can discourage industrial managers and entrepreneurs who see high absenteeism, long waiting times, customer dissatisfaction, limited support, and high labor turnover of both customers, companies, and economies. Indeed, the way of communicating services to potential customers, the quality of services to existing customers, and the ways in which customer relationships are managed do have a big impact on the faithful customer base and growth of the business. The identification of the possible discomfort zones and the timely identification of the sense of humor, and courteous and professional words of the operators certainly support corporate image, helping the company in the communication activities and in improving its reputation. The capture of useful business information can also lead to further business activities. Here are some reasons why it might be time to upgrade to an AI assisted systems:

**1. Improved Customer Experience:**
Transitioning to AI-assisted systems in contact centers is not just a trend but a necessity. A study by Accenture found that 57% of customers are willing to switch to a competitor after just one bad experience. Embracing this technology can help contact centers stay competitive and deliver exceptional service in an increasingly demanding marketplace by offering compelling solutions that can dynamically manage queues, significantly reduce wait times for customers by analyzing caller data in real-time and ensures calls are directed to the most suitable agent, enhancing the chances of a first-call resolution.

**2. Enhanced Agent Performance:**
According to a report by Salesforce, AI can boost agent productivity by up to 40%, allowing them to handle more queries efficiently. AI tools provide agents with instant access to customer information and recommended actions, enabling faster and more accurate responses. These automated systems handle routine inquiries and tasks, freeing up agents to focus on more complex issues. 

**3. Operational Efficiency:**
AI systems require less manual setup and management, reducing the risk of errors and the need for specialized expertise. Deloitte's research indicates that AI can reduce contact center costs by up to 20% by automating routine tasks and optimizing agent performance. This automation adjusts to changing call volumes without disrupting operations.


**Solution Components and Purposes**
Companies want to make sense of the conversations happening in their contact centers to improve productivity, gain insight, monitor quality, and react quickly to events as they unfold. There are many innovative technologies that are transforming the contact center, and below are some of the components and services leveraged for the sake of this tutorial and the purpose each of these services serve.

- **Amazon Connect:** 
A cloud-based contact center solution that enables businesses to deliver superior customer service at a lower cost. This Amazon service will be used to handle customer calls and stream audio data to Amazon Kinesis.
- **Amazon Kinesis:** 
A fully managed service that makes it easy to collect, process, and analyze real-time, streaming data. It will be used to stream audio data from Amazon Connect and process it for analysis.
**Symbl.ai:** 
- A conversational intelligence platform that analyzes and generates insights from natural language conversations. It will be used to transcribe and analyze audio data, set up trackers, and implement Retrieval Augmented Generation (RAG) using Nebula LLM.
- **Nebula LLM:** 
A large language model that generates human-like text based on input prompts. It will be used to generate answers to customer queries based on the knowledge base and similar content.


**Prerequisites**
You will need access to the following:

- A pair of Access and Secret keys for the AWS account where Amazon Connect is configured.
- A pair of appId and secret for Symbl.ai, which you can get from the platform’s main page. We use these to retrieve a temporary access token.
- An API Key for Nebula LLM, which you get by joining the beta wait list.

**Set up streaming for phone conversations**
Streaming integration brings new opportunities to react to events as they happen, instead of waiting for transactions that process afterwards. Organizations who have realized this are using it for real-time analytics, machine learning, and other decision-making services. Here, you will learn about the use of the Amazon Connect (AC) and Amazon Kinesis (AK) services, extending to other Amazon features and Artificial Intelligence with Symbl.ai. API documentation details may change, but this article provides the basic ideas that help developers further explore and use these services.

Now to dive deep into the workings of this solution, we start by configuring all the neccessary credentials. 

**Step 1: Set Up Amazon Connect**
Create an Amazon Connect Instance:

*Navigate to the Amazon Connect console*
Create a new Amazon Connect instance following the setup wizard.

*Configure Contact Flows:*
- Go to the Amazon Connect dashboard.
- Create or edit a contact flow to manage incoming calls.
- Add a block to start streaming audio to Amazon Kinesis.

**Step 2: Set Up Amazon Kinesis**
Create a Kinesis Stream:

Go to the Amazon Kinesis console.
- Create a new data stream and give it a name (e.g., ConnectAudioStream).
- Set the number of shards based on your expected call volume.
- Stream Data from Amazon Connect to Kinesis:

Modify the contact flow in Amazon Connect to add an AWS Lambda function that starts streaming audio to Kinesis.
Here’s the Lambda function to start streaming:

```import boto3
import json

def lambda_handler(event, context):
    kinesis = boto3.client('kinesis')
    
    # Assuming 'Audio' is already base64 encoded in the event
    audio_data = event['Details']['ContactData']['MediaStreams']['Customer']['Audio']
    
    try:
        response = kinesis.put_record(
            StreamName='ConnectAudioStream',
            Data=audio_data,
            PartitionKey='partitionKey'
        )
        print("PutRecord Response: ", response)
        
        return {
            'statusCode': 200,
            'body': json.dumps('Audio streaming started')
        }
        
    except Exception as e:
        print("Error putting record into Kinesis: ", str(e))
        return {
            'statusCode': 500,
            'body': json.dumps('Error streaming audio')
        }```


**Use the Telephony API**
Create a new file in your script folder called telephony.py. The purpose of creating this file is to authorizes developers with the Telephony API and uses PSTN to call a given phone number. The sample also returns a conversation ID, which can be used to generate conversation intelligence.

```import symbl

app_id = "<APP_ID>"
app_secret = "<APP_SECRET>"
phone_number = "<PHONE_NUMBER>"
email = "<EMAIL>"


connection_object = symbl.Telephony.start_pstn(
  credentials={"app_id": app_id, "app_secret": app_secret},
  phone_number=phone_number,
  actions = [
    {
      "invokeOn": "stop",
      "name": "sendSummaryEmail",
      "parameters": {
        "emails": [
          email
        ],
      },
    },
  ]
)

print("Conversation ID: " + connection_object.conversation.get_conversation_id())```

Where:

<APP_ID> and <APP_SECRET> are your App ID and Secret from your Symbl.ai Home page.
<NAME> is the name of the person speaking.
<EMAIL> is the email address of the person speaking. If provided, when the audio stream ends, the Streaming API sends an email with conversation intelligence to the given address.
To run the code sample:

On the command line, go to your Python project directory.

Run the code sample.

python3 telephony.py
When you run the code, the Telephony API places a phone call to the given number and captures any spoken conversation.

**Generate Conversational Intelligence:**
Use the conversation ID obtained from the telephony.py file to retrieve messages and sentiment data from Symbl.ai.

```import requests

base_url = "https://api.symbl.ai/v1/conversations/{conversation_id}/messages"
conversation_id = 'your_conversation_id'
access_token = 'your_access_token'

url = base_url.format(conversation_id=conversation_id)

headers = {
    'Authorization': 'Bearer ' + access_token,
    'Content-Type': 'application/json'
}

params = {
    'verbose': True, 
    'sentiment': True 
}

response = requests.get(url, headers=headers, params=params)

if response.status_code == 200:
    messages = response.json()['messages']
    for message in messages:
        print(f"Message ID: {message['id']}")
        print(f"Text: {message['text']}")
        print(f"Sentiment: {message['sentiment']['polarity']['score']}")
        print("------")
else:
    print("Failed to get messages", response.text)```


**Determine When Call Center Agents Receive AI Assistance**
To determine when agents can receive real-time AI assistance during remote troubleshooting calls, you need to create trackers and configure triggers that activate the running of the created tracker. In this section, we will configure trackers on Symbl.ai using common troubleshooting phrases as triggers.

**Step-by-Step Guide**
- Set Up Trackers with Symbl.ai

**Login to Symbl.ai:**
Go to the Symbl.ai website and log in to your account. You will be directed to the Symbl.ai dashboard.
**Create a Custom Tracker:**
- Navigate to Tracker Management.
- Click on Create Custom Tracker.
- Configure the Custom Tracker:

You will be directed to a page where you need to fill in the following fields:
- Tracker Name: Provide a name for the tracker.
- Description: Describe the purpose of the tracker.
- Categories: Choose "Contact Center" as the category.
- Language: Select the language for the tracker.
- Vocabulary: Add at least four phrases that will serve as troubleshooting triggers. For example, "restart", "reboot", "reset", "troubleshoot", "error", and "not working".

**View the Tracker:**
After creating the custom tracker, go to the API Explorer and click on Trackers to see the newly created tracker

Example Troubleshooting Triggers:
```trackers = [
    {
        "name": "Troubleshooting",
        "vocabulary": ["restart", "reboot", "reset", "troubleshoot", "error", "not working"]
    }
]```

By following these steps, you can effectively determine when call center agents receive AI assistance using Symbl.ai. Setting up trackers with specific troubleshooting phrases ensures that AI assistance is provided at the right moments, enhancing the efficiency and effectiveness of your call center operations.

**Provide Agents with real-time AI assistance**
It is time to put all that have been discussed into an actionable real-time perspective by providing a practical walk-through of a sample use case that provide an agent wuth real-time assistance during a conversation with a client. At this point in this tutorial, it is assumed that you have created an account on the Symbl.ai platform, and have access to Nebula LLM and have completed the necessary authentication. If you require assistance on any of these steps, refer to our docs on getting started and how to authenticate. If you need access to the Nebula Playground and model API visit https://symbl.ai.

**Implementing Real-Time AI Assistance**
Here's how you can incorporate Amazon Connect, Amazon Kinesis, and Nebula LLM in the workflow:

We start by configuring Amazon Connect and Kinesis Stream:

```import boto3

# Create a Kinesis client
kinesis_client = boto3.client('kinesis')

# Create a Kinesis stream
response = kinesis_client.create_stream(
    StreamName='YourKinesisStreamName',
    ShardCount=1
)```

Set Up Kinesis Stream to Receive Audio Data from Amazon Connect:
In the Amazon Connect console, configure the instance to stream call audio data to the Kinesis stream created above.

Read from Kinesis Stream and Send to Symbl.ai:

```import boto3
import requests
import json

# Initialize the Kinesis client
kinesis_client = boto3.client('kinesis')

# Function to read data from Kinesis stream
def read_from_kinesis():
    response = kinesis_client.get_shard_iterator(
        StreamName='YourKinesisStreamName',
        ShardId='shardId-000000000000',
        ShardIteratorType='LATEST'
    )

    shard_iterator = response['ShardIterator']
    records_response = kinesis_client.get_records(ShardIterator=shard_iterator, Limit=10)

    for record in records_response['Records']:
        audio_chunk = record['Data']  # Extract the audio chunk

        # Send audio data to Symbl.ai for transcription
        symbl_response = requests.post(
            "https://api.symbl.ai/v1/process/audio",
            headers={
                'Authorization': 'Bearer ' + symbl_api_key,
                'Content-Type': 'application/json'
            },
            data=json.dumps({
                'audio_url': 's3://your-audio-file-path'
            })
        )

        transcription = symbl_response.json()
        print(transcription)  # Print or process the transcription

        # Send transcription to Nebula LLM for real-time assistance
        assist_agent(transcription)

def assist_agent(transcription):
    url = "https://api-nebula.symbl.ai/v1/model/chat/streaming"
    payload = json.dumps({
        "max_new_tokens": 1024,
        "system_prompt": "You are a service support assistant. You help users troubleshoot issues with purchased products and services. You are respectful, professional and you always respond politely.",
        "messages": [
            {
                "role": "human",
                "text": transcription['text']
            }
        ]
    })
    headers = {
        'ApiKey': NEBULA_API_KEY,
        'Content-Type': 'application/json'
    }

    response = requests.request("POST", url, headers=headers, data=payload)
    print(response.json())  # Real-time AI assistance response

# Continuously read from Kinesis stream
while True:
    read_from_kinesis()```

This script demonstrates the end-to-end process of streaming audio data from Amazon Connect via Amazon Kinesis, transcribing it using Symbl.ai, and providing real-time AI assistance with Nebula LLM.

By integrating Amazon Connect and Amazon Kinesis with Symbl.ai and Nebula LLM, you can create a robust system for real-time AI assistance in your call center. This setup ensures that agents receive immediate support upon the trigger of troubleshooting phrases during customer interactions, improving efficiency and customer satisfaction.

**Implement retrieval augmented generation (RAG) with call center training materials**
To implement retrieval augmented generation (RAG) with call center training materials using the Nebula API, you'll need to adapt the provided code snippet. RAG is a technique that combines retrieval-based and generation-based methods, which typically involves fetching relevant documents or pieces of information to help generate a more informed and accurate response.

**Step-by-Step Implementation**
**Step 1: Setup**
Ensure you have your API key and the necessary endpoint URLs.

**Step 2: Retrieve Relevant Information**

```import torch
from transformers import BartForConditionalGeneration, BartTokenizer
from elasticsearch import Elasticsearch
import requests
import json

# Initialize Elasticsearch client
es = Elasticsearch()

# Initialize BART model and tokenizer
model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')
tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')

# Symbl.ai API key and URL
SYMBL_API_KEY = 'YOUR_SYMBL_API_KEY'
SYMBL_URL_TRACKER = 'https://api.symbl.ai/v1/process/text'

def symbl_extract_context(query):
    headers = {
        'Authorization': f'Bearer {SYMBL_API_KEY}',
        'Content-Type': 'application/json'
    }
    payload = {
        'messages': [{'payload': {'content': query, 'contentType': 'text/plain'}}]
    }
    response = requests.post(SYMBL_URL_TRACKER, headers=headers, data=json.dumps(payload))
    response_data = response.json()

    # Extract key phrases and topics from Symbl.ai response
    key_phrases = [phrase['text'] for phrase in response_data.get('context', {}).get('keyPhrases', [])]
    topics = [topic['text'] for topic in response_data.get('context', {}).get('topics', [])]
    
    # Extract matched phrases from tracker
    trackers = response_data.get('trackers', {}).get('matches', [])
    matched_phrases = [match['text'] for match in trackers]

    # Combine key phrases, topics, and matched phrases for enhanced retrieval
    context_terms = key_phrases + topics + matched_phrases
    return ' '.join(context_terms)

def retrieve_training_materials(query):
    # Enhance query with context extraction using Symbl.ai
    enhanced_query = symbl_extract_context(query)
    
    # Search for relevant documents in Elasticsearch
    search_response = es.search(index='knowledge_base', body={'query': {'match': {'content': enhanced_query}}})
    relevant_docs = [hit['_source']['content'] for hit in search_response['hits']['hits']]
    return relevant_docs

def generate_response(query, context):
    # Combine the query with retrieved context
    combined_input = query + " " + " ".join(context)
    
    # Tokenize the combined input
    input_ids = tokenizer.encode(combined_input, return_tensors='pt', truncation=True, max_length=1024)
    
    # Generate the response
    output = model.generate(input_ids=input_ids, max_length=150, num_return_sequences=1)
    response = tokenizer.decode(output[0], skip_special_tokens=True)
    
    return response

def rag(query):
    # Retrieve relevant documents
    relevant_docs = retrieve_training_materials(query)
    
    # Generate response with context
    response = generate_response(query, relevant_docs)
    
    return response```

# Test the RAG model
query = 'How do I troubleshoot a slow computer?'
response = rag(query)
print(response)

In the code above, Symbl.ai's tracking API was leveraged to check if the query contains any of the predefined key phrases and vocabulary. You can integrate this check into your system to enhance the query before passing it to Elasticsearch for document retrieval.

**Explanation**
**Symbl.ai Trackers API:**
symbl_extract_context includes logic to call Symbl.ai’s tracker API and extract matches from the predefined tracker.
The payload for the Symbl.ai API call remains the same, but the response handling now checks for tracker matches in the trackers section of the response.

**Enhanced Query:**
This function combines key phrases, topics, and matched phrases from the tracker to form a more comprehensive enhanced query.

**Document Retrieval:**
Elasticsearch uses the enhanced query to search for relevant documents.
By using the existing tracker on Symbl.ai, the RAG system becomes more efficient in identifying relevant phrases and topics, thus improving the overall accuracy and relevance of the generated responses.

**Set up a simple agent assist chatbot**
To set up a simple agent assist chatbot that uses retrieval-augmented generation (RAG) with Elasticsearch and BART, integrated with Symbl.ai for context extraction and trackers, you can follow the steps below. This example includes the necessary code to build a basic chatbot using these components.

** Requirements **
Install the required libraries:
pip install torch transformers elasticsearch requests

Ensure you have an Elasticsearch instance running and Symbl.ai API access with your API key.

** Code Implementation **
Here is the complete implementation of a simple agent assist chatbot:

```import torch
from transformers import BartForConditionalGeneration, BartTokenizer
from elasticsearch import Elasticsearch
import requests
import json

# Initialize Elasticsearch client
es = Elasticsearch()

# Initialize BART model and tokenizer
model = BartForConditionalGeneration.from_pretrained('facebook/bart-large')
tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')

# Symbl.ai API key and URL
SYMBL_API_KEY = 'YOUR_SYMBL_API_KEY'
SYMBL_URL_TRACKER = 'https://api.symbl.ai/v1/process/text'

# Function to extract context using Symbl.ai
def symbl_extract_context(query):
    headers = {
        'Authorization': f'Bearer {SYMBL_API_KEY}',
        'Content-Type': 'application/json'
    }
    payload = {
        'messages': [{'payload': {'content': query, 'contentType': 'text/plain'}}]
    }
    response = requests.post(SYMBL_URL_TRACKER, headers=headers, data=json.dumps(payload))
    response_data = response.json()

    # Extract key phrases, topics, and matched phrases from Symbl.ai response
    key_phrases = [phrase['text'] for phrase in response_data.get('context', {}).get('keyPhrases', [])]
    topics = [topic['text'] for topic in response_data.get('context', {}).get('topics', [])]
    trackers = response_data.get('trackers', {}).get('matches', [])
    matched_phrases = [match['text'] for match in trackers]

    # Combine key phrases, topics, and matched phrases for enhanced retrieval
    context_terms = key_phrases + topics + matched_phrases
    return ' '.join(context_terms)

# Function to retrieve relevant documents from Elasticsearch
def retrieve_training_materials(query):
    # Enhance query with context extraction using Symbl.ai
    enhanced_query = symbl_extract_context(query)
    
    # Search for relevant documents in Elasticsearch
    search_response = es.search(index='knowledge_base', body={'query': {'match': {'content': enhanced_query}}})
    relevant_docs = [hit['_source']['content'] for hit in search_response['hits']['hits']]
    return relevant_docs

# Function to generate response using BART model
def generate_response(query, context):
    # Combine the query with retrieved context
    combined_input = query + " " + " ".join(context)
    
    # Tokenize the combined input
    input_ids = tokenizer.encode(combined_input, return_tensors='pt', truncation=True, max_length=1024)
    
    # Generate the response
    output = model.generate(input_ids=input_ids, max_length=150, num_return_sequences=1)
    response = tokenizer.decode(output[0], skip_special_tokens=True)
    
    return response

# Function to handle RAG process
def rag(query):
    # Retrieve relevant documents
    relevant_docs = retrieve_training_materials(query)
    
    # Generate response with context
    response = generate_response(query, relevant_docs)
    
    return response

# Main function to run the chatbot
def main():
    print("Welcome to the Agent Assist Chatbot!")
    while True:
        user_query = input("You: ")
        if user_query.lower() in ['exit', 'quit']:
            print("Goodbye!")
            break
        response = rag(user_query)
        print(f"Bot: {response}")

# Run the chatbot
if __name__ == "__main__":
    main()```

**Explanation**
**Initialize Components:**
- Elasticsearch client to retrieve documents.
- BART model and tokenizer for generating responses.
- Symbl.ai API key and URL for context extraction.
- Symbl.ai Context Extraction:

After initialization of required components, the symbl_extract_context function sends the query to Symbl.ai to extract key phrases, topics, and matched phrases from the predefined tracker.

**Document Retrieval:**
retrieve_training_materials function uses the enhanced query to search for relevant documents in Elasticsearch.

** Response Generation **:
The generate_response function combines the user query with the retrieved documents' content and generates a response using the BART model.

**RAG Process:**
The rag function integrates document retrieval and response generation to provide a coherent answer to the user's query.

**Chatbot Interaction:**
main function handles the user interaction in a loop, continuously processing user queries and providing responses until the user decides to exit.
This setup provides a basic agent assist chatbot that leverages retrieval-augmented generation to provide informed and contextually relevant responses to user queries.

In this tutorial, you have been shown how to successfully build a simple agent assist chatbot using Retrieval-Augmented Generation (RAG) with Elasticsearch and BART, enhanced by Symbl.ai's context extraction capabilities. This chatbot can significantly aid call center agents by providing quick, contextually relevant responses to customer inquiries, thus improving response times and accuracy. Customers benefit from receiving precise and helpful information swiftly, leading to a better overall experience and increased satisfaction.

To take this solution further, consider integrating advanced features such as multi-turn conversation handling to maintain context across multiple interactions. Additionally, incorporating sentiment analysis could help agents prioritize and tailor their responses based on the customer's emotional state. Another improvement could be using more sophisticated models like GPT-4 for enhanced language understanding and response generation. Finally, expanding the knowledge base in Elasticsearch with a wider array of documents and regularly updating it with new information can ensure that the chatbot remains relevant and accurate.
